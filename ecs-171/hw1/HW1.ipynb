{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-KaNrM6RgvGY","colab_type":"code","outputId":"2842a0cb-fd84-4345-97ac-641279e2c43e","executionInfo":{"status":"ok","timestamp":1588966124544,"user_tz":420,"elapsed":315,"user":{"displayName":"Han Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAW5WUTfqOcCXb6sp06ZdXF8QaAbtryt_OmGUX=s64","userId":"14912026719267396344"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## Mount from professor's drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jybEa3xahnav","colab_type":"text"},"source":["**PROBLEM 1**"]},{"cell_type":"code","metadata":{"id":"NZOAqhP-VnQs","colab_type":"code","outputId":"37434ed8-05c2-4bfa-9384-ee4105e1e151","executionInfo":{"status":"ok","timestamp":1588967091982,"user_tz":420,"elapsed":6721,"user":{"displayName":"Han Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAW5WUTfqOcCXb6sp06ZdXF8QaAbtryt_OmGUX=s64","userId":"14912026719267396344"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["## bestK() FUNCTION\n","def bestK(X, Y, maxK, maxRow):\n","  \n","  # Get predictors of knn from X and Y and set allK = True, leave1out = True\n","  knnout, nn = kNN(X, Y, X, maxK, allK=True, leave1out=True)\n","\n","  # Create a list for all best K values and MAPE\n","  bestk_values = []\n","  MAPE_values = []\n","\n","  # Loop through the rows and columns of data based on maxRows and knnout predictors to get MAPE and besk K values\n","  for i in range(0, maxRow):\n","    for j in range(0, len(knnout)):\n","      # Get Y predictors and outcomes \n","      Y_pred = knnout[i][j]\n","      Y_outcome = Y.iloc[i]\n","\n","      # Get MAPE values\n","      MAPE = findOverallLoss(Y_pred, Y_outcome)\n","      MAPE_values.append(MAPE)\n","\n","    # Get best K value by the index of the lowest MAPE value\n","    bestk = MAPE_values.index(min(MAPE_values))\n","    bestk_values.append(bestk)\n","  \n","  print(bestk_values)\n","\n","  # Get the most common K values:\n","  from scipy import stats as s\n","  most_common_k = int(s.mode(bestk_values)[0])\n","  print(most_common_k)\n","\n","## findOverallLoss() FUNCTION\n","def findOverallLoss(ypreds, Y):\n","  err = abs(ypreds - Y)\n","  MAPE = err.mean()\n","  return MAPE\n","\n","## kNN() FUNCTION\n","def kNN(X,Y,newx,k,regress=True,allK=False,leave1out=False,scaleX=True,scaler=StandardScaler()):\n","\n","  import warnings\n","  warnings.filterwarnings('ignore')\n","\n","  import numpy as np\n","\n","  from sklearn.neighbors import KNeighborsClassifier \n","  from sklearn.neighbors import KNeighborsRegressor\n","\n","  from sklearn.preprocessing import StandardScaler\n","  from sklearn.preprocessing import MinMaxScaler\n","  from sklearn.preprocessing import RobustScaler\n","\n","  from statistics import mean \n","  from statistics import mode\n","  from collections import Counter\n","\n","  def kNNtype(neighbs,regress):\n","    if regress:\n","      knn = KNeighborsRegressor(n_neighbors=neighbs)\n","    else:\n","      knn = KNeighborsClassifier(n_neighbors=neighbs)\n","    return knn\n","\n","  if scaler != StandardScaler():\n","    scaler=scaler\n","\n","\n","# Update: for row subsets/test sets in hw; fitting the scaling function should be done separate,\n","# so the same can be applied to train and test data (or X and newx) \n","  if scaleX == True:\n","    # scale should be fit to X/train\n","    scaler.fit(X)\n","    columns_X = [list(X.columns)]\n","    for feature in columns_X:\n","      X[feature] = scaler.transform(X[feature])\n","      newx[feature] = scaler.transform(newx[feature])\n","  \n","\n","  knn_all = pd.DataFrame()\n","  if allK == True:\n","    if leave1out == True:\n","      nn_all = []\n","      for j in list(newx.index.values.tolist()): #(4/13)\n","      #for j in list(Y.index.values.tolist()): \n","        knn_row = []\n","        knn = kNNtype(k+1,regress)\n","        knn.fit(X, Y)\n","        test = pd.DataFrame(newx.loc[j,:])\n","        nn = knn.kneighbors(test.T)[1][0]\n","        for i in range(2,k+1):\n","          nn1 = nn[1:i] # leave one out\n","          test = list(Y.iloc[nn1])\n","          if regress:\n","            test = mean(test)\n","          else:\n","            c = Counter(test)\n","            l = list(c.values())\n","            ind = l.index(max(c.values()))\n","            test = list(c.keys())[ind]\n","            # count number of times the max class occurs and if there is a tie\n","            # choose the second class with the max if index is even\n","            if (l.count(max(l))) > 1 and (j % 2 !=0):\n","              l[ind] = 0\n","              ind = l.index(max(c.values()))\n","              test = list(c.keys())[ind]\n","\n","          knn_row.append(test)\n","        knn_row = pd.DataFrame(knn_row)\n","        knn_all = [knn_all, knn_row]\n","        knn_all = pd.concat(knn_all,axis=1, ignore_index=True)\n","        nn_all.append(list(nn1))\n","      nn_all = np.array(nn_all)\n","    else:\n","        for i in range(1,k+1):\n","          knn = kNNtype(i,regress)\n","          knn.fit(X, Y)\n","          test = knn.predict(newx)\n","          knn_row = pd.DataFrame(test).T\n","          knn_all = [knn_all, knn_row]\n","          knn_all = pd.concat(knn_all,axis=0, ignore_index=True)\n","        nn_all = knn.kneighbors(newx)[1]\n","  else:\n","    if leave1out == True:\n","      knn_row = []\n","      #for j in list(Y.index.values.tolist()):\n","      for j in list(newx.index.values.tolist()): # (4/13)\n","        knn = kNNtype(k,regress)\n","        knn.fit(X, Y)\n","        test = pd.DataFrame(newx.loc[j,:])\n","        nn = knn.kneighbors(test.T)[1][0]\n","        nn1 = nn[1:len(nn)]\n","\n","        test = list(Y.iloc[nn1])\n","        if regress:\n","            test = mean(test)\n","        else:\n","          c = Counter(test)\n","          l = list(c.values())\n","          ind = l.index(max(c.values()))\n","          test = list(c.keys())[ind]\n","          # count number of times the max class occurs and if there is a tie\n","          # choose the second class with the max if index is even\n","          if (l.count(max(l))) > 1 and (j % 2 !=0):\n","            l[ind] = 0\n","            ind = l.index(max(c.values()))\n","            test = list(c.keys())[ind]\n","\n","        knn_row.append(test)\n","      knn_all = pd.DataFrame(knn_row).T\n","      nn_all = nn1\n","    else:\n","        knn = kNNtype(k,regress)\n","        knn.fit(X, Y)\n","        test = knn.predict(newx)\n","        knn_all = pd.DataFrame(test)\n","        nn_all = knn.kneighbors(newx)[1]\n","\n","  return knn_all, nn_all\n","\n","## MAIN CODES ##\n","my_path = '/content/drive/My Drive/ecs171_yancey/Lecture_Notes/Chapter_1/day1.csv'\n","import pandas as pd\n","day1 = pd.read_csv(my_path)\n","\n","day1 = day1.loc[:,[\"workingday\",\"temp\",\"atemp\",\"hum\",\"windspeed\",\"tot\"]]\n","X = day1.iloc[:,0:5]\n","Y = day1.tot\n","\n","bestK(X, Y, 30, 5)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["[17, 32, 58, 58, 116]\n","58\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OxZZiFndzaUd","colab_type":"text"},"source":["**PROBLEM 2**"]},{"cell_type":"code","metadata":{"id":"VwLvagicBQpF","colab_type":"code","outputId":"512469a8-8a11-4a66-c9a6-f8b83743aecc","executionInfo":{"status":"ok","timestamp":1588966788789,"user_tz":420,"elapsed":4518,"user":{"displayName":"Han Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAW5WUTfqOcCXb6sp06ZdXF8QaAbtryt_OmGUX=s64","userId":"14912026719267396344"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["## p_hack() FUNCTION\n","def p_hack(X, Y, n_subsets, maxK):\n","\n","  # Since there are n subsets to analyze, we get the length of each subset by length of X divided by n_subsets\n","  import math \n","  subset_length = math.floor(len(X) / n_subsets)\n","\n","  # Create list for besk K values and MAPE values\n","  bestk_values = []\n","  MAPE_values = []\n","  bestk_of_subset = []\n","\n","  # Loop through X and Y to get each subset from them\n","  for i in range(0, n_subsets):\n","    # Get start and end indices of the subset\n","    start = i * subset_length\n","    end = (i+1) * subset_length\n","\n","    # Get the subset of X and Y\n","    subset_X = X[start:end]\n","    subset_Y = Y[start:end]\n","\n","    # Get predictors of knn from X and Y and set allK = True, leave1out = True\n","    knnout, nn = kNN(subset_X, subset_Y, subset_X, maxK, allK=True,leave1out=True)\n","\n","    # Loop through each subset of Y to find the best K values\n","    for row in range(0, len(subset_Y)): \n","      for col in range(len(knnout)):\n","        Y_pred = knnout[row][col] # Get predicted values of Y\n","        Y_outcome = Y.iloc[row] # Get outcomes of Y\n","\n","        # Get MAPE values\n","        MAPE = findOverallLoss(Y_pred, Y_outcome)\n","        MAPE_values.append(MAPE)\n","\n","      # Find best K values with the lowest MAPE value (lowest loss)\n","      bestk = MAPE_values.index(min(MAPE_values))\n","      bestk_values.append(bestk)\n","\n","    # Get the most common K using mode and add to bestK for a subset of X\n","    from scipy import stats as s\n","    most_common_k = int(s.mode(bestk_values)[0])\n","    bestk_of_subset.append(most_common_k)\n","\n","  print(bestk_of_subset)\n","  \n","  # Calculate variance from best K values of each subset\n","  import statistics\n","  variance = statistics.variance(bestk_of_subset)\n","  print(variance)\n","\n","## findOverallLoss() FUNCTION\n","def findOverallLoss(ypreds, Y):\n","  err = abs(ypreds - Y)\n","  MAPE = err.mean()\n","  return MAPE\n","\n","## MAIN CODES ##\n","my_path = '/content/drive/My Drive/ecs171_yancey/Lecture_Notes/Chapter_1/day1.csv'\n","day1 = pd.read_csv(my_path)\n","day1 = day1.loc[:,[\"workingday\",\"temp\",\"atemp\",\"hum\",\"windspeed\",\"tot\"]]\n","X = day1.iloc[:,0:5]\n","Y = day1.tot\n","\n","p_hack(X, Y, 30, 5)"],"execution_count":39,"outputs":[{"output_type":"stream","text":["[22, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93]\n","168.03333333333333\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DfWteJ9mDhFn","colab_type":"text"},"source":["**PROBLEM 3**"]},{"cell_type":"code","metadata":{"id":"tDB6pCLmVBZp","colab_type":"code","colab":{}},"source":["## Should be run in RStudio Code\n","\n","library(regtools)\n","data(day)\n","# head(day)\n","d <- day[c('temp','atemp','hum','windspeed','casual','registered','cnt')]\n","lmout <- lm(cnt ~ .,data=d)\n","xd = preprocessx(d[,-5],10)\n","knnout <- knnest(d$cnt,xd,10)\n","parvsnonparplot(lmout,knnout)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ifibpBm2fcfa","colab_type":"text"},"source":["**PROBLEM 4**"]},{"cell_type":"code","metadata":{"id":"INROMtrDffa-","colab_type":"code","outputId":"ddb59978-534c-4445-ff26-912c5ca8d7b3","executionInfo":{"status":"ok","timestamp":1588967234759,"user_tz":420,"elapsed":290,"user":{"displayName":"Han Nguyen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgAW5WUTfqOcCXb6sp06ZdXF8QaAbtryt_OmGUX=s64","userId":"14912026719267396344"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["## atRisk(rows,k,path)\n","def atRisk(rows,k,path):\n","  import pandas as pd\n","  vert = pd.read_csv(path,sep=' ',header=None)\n","    \n","  # get X and Y data\n","  X = vert.iloc[:,0:6]\n","  from sklearn.preprocessing import LabelEncoder\n","  le = LabelEncoder()\n","  vert.iloc[:,6] = le.fit_transform(vert.iloc[:,6])\n","  Y = vert.iloc[:,6]\n","\n","  # Get knn via Classifier and fit the knn with X and Y\n","  from sklearn.neighbors import KNeighborsClassifier\n","  knn = KNeighborsClassifier(n_neighbors=k)\n","  knn.fit(X, Y)\n","    \n","  # Get test data and predict probabilities\n","  test = pd.DataFrame(X.iloc[0:11,:])\n","  array = knn.predict_proba(test)\n","\n","  # Loop through 2D array to check categories and replace values: \n","  for i in range(0,len(array)):\n","    for j in range(0,len(array[0])):\n","      if array[i][j] < 0.3:\n","        array[i][j] = 0\n","      elif array[i][j] >= 0.3 and array[i][j] < 0.5: \n","        array[i][j] = 2\n","      elif array[i][j] >= 0.5:\n","        array[i][j] = 1\n","    \n","  # Display array\n","  print(array)\n","\n","\n","## MAIN CODES ## \n","my_path = \"/content/drive/My Drive/ecs171_yancey/Lecture_Notes/Chapter_2/column_3C.dat\"\n","atRisk(30, 5, my_path)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["[[1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [1. 0. 0.]\n"," [2. 1. 0.]\n"," [2. 1. 0.]\n"," [1. 2. 0.]\n"," [1. 2. 0.]\n"," [1. 0. 0.]\n"," [1. 2. 0.]]\n"],"name":"stdout"}]}]}