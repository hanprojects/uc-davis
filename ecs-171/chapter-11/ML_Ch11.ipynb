{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ML_Ch11.ipynb","provenance":[],"mount_file_id":"1_k-5FgatlaNNmD7szUCVzuH2t8AjbyWx","authorship_tag":"ABX9TyPbC7u43Wq303BH7TpyLnZp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xjF-wMRekbw6","colab_type":"text"},"source":["\n","# Chapter 11: NNs"]},{"cell_type":"markdown","metadata":{"id":"9EEhHg6OKlat","colab_type":"text"},"source":["* problems include black box, many hyperparmeters, run time, convergence\n","\n","* inspired by biology of human thought\n","\n","  * eg. outputs fire/activate (ouputs 1), or not (0), hidden layers (output from one to next), and activation functions allow for outputs of more then just 1 or 0\n","\n","* overview of how it works:\n","\n","  * layers: inputs fed to inner layers connected from one to another all the way to outputs\n","\n","  * outputs of layers are fed through an activation function (analagous to SVM kernel)\n","\n","  * final output is usually a single number in regression, or c class probabilities in classification"]},{"cell_type":"markdown","metadata":{"id":"XuSrXK7bof0M","colab_type":"text"},"source":["## 11.1. Example: Vertebrae Data"]},{"cell_type":"markdown","metadata":{"id":"vF9bVD64olHV","colab_type":"text"},"source":["* we will use the default parameters shown in the output below\n","\n","* MLP: ***multi-layer pereptron*** from `sklearn` has regression and classification methods (eg. MLPregressor)\n","\n","* trains using backpropogation (see week 0 slides and lecture in intro to NN)\n","\n","  * cross-entropy loss\n","\n","* weights are updated with some randomness so random_state input allows reproducibility\n","\n","  * *non-convex loss function* (eg. there exists more than one local minimum)\n","  \n","  * different ***random weight initializations*** can produce different validation accuracies\n","\n","* `relu` function is default activation function\n","\n","  * nothing to do with GLM logistic model application\n","\n","  * can also use: '`identity`', '`logistic`', '`tanh`'\n","\n","      * activation function use has nothing to do with GLM use\n","\n","* possible solvers (default is `adam`):\n","\n","  * `lbfgs` is an optimizer in the family of quasi-Newton methods\n","\n","  * `sgd` :stochastic gradient descent (converges faster for smaller datasets)\n","\n","  * `adam` : stochastic gradient-based optimizer (proposed by Kingma, Diederik, and Jimmy Ba) (better for larger data)\n","\n","\n","* **ADAM**: an adaptive learning rate method\n","\n","* uses estimations of first and second moments of gradient to adapt the learning rate for each weight of the neural network\n","\n","  * combination of RMSprop and SGD with momentum\n","  \n","  * uses the squared gradients to scale the learning rate like RMSprop \n","  \n","  * momentum is moving average of the gradient (instead of gradient itself like SGD with momentum)\n","\n","\n","* trains using some form of **gradient descent** and the gradients are calculated using **Backpropagation**\n","\n","  * make sure you know these from week 0 NN intro\n","\n","\n","*  For each class, the raw output passes through the logistic function"]},{"cell_type":"code","metadata":{"id":"ZkuSiVgGO8he","colab_type":"code","outputId":"325a2938-8d28-4074-de45-240b7379a545","executionInfo":{"status":"ok","timestamp":1591034333102,"user_tz":420,"elapsed":3825,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","my_path = '/content/drive/My Drive/ecs171_yancey/Lecture_Notes/Chapter_2/column_3C.dat'\n","vert = pd.read_csv(my_path, sep=' ',header=None)\n","\n","\n","from sklearn.neural_network import MLPClassifier\n","X_train, X_test, y_train, y_test = train_test_split(vert.iloc[:,0:5], vert.iloc[:,6], test_size=20)\n","\n","clf = MLPClassifier(solver='sgd',hidden_layer_sizes=(3, ), random_state=1)\n","clf.fit(X_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n","              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n","              hidden_layer_sizes=(3,), learning_rate='constant',\n","              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n","              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n","              power_t=0.5, random_state=1, shuffle=True, solver='sgd',\n","              tol=0.0001, validation_fraction=0.1, verbose=False,\n","              warm_start=False)"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"vLjnTONJjko-","colab_type":"text"},"source":["* `hidden_layer_sizes=(3,)` means 1 hidden layer and 3 neurons are specified\n","\n","* we will have 6 neurons in the input layer since we have 6 fetaures,  3 neurons in the output layer since we have 3 classes, hidden layer in between\n","\n","\n","* weighted sum is fed into output layer (again, please, see week 0 lecture notes/video)\n","\n","  * minimize sum of squared errors to compute weights using sgd \n","\n"]},{"cell_type":"code","metadata":{"id":"bXzDXgyhvglJ","colab_type":"code","outputId":"f58247bd-0ef7-48ae-b91c-25fe3e2c4873","executionInfo":{"status":"ok","timestamp":1591034333103,"user_tz":420,"elapsed":3806,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["clf.intercepts_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([ 0.29525839, -0.15850658,  0.10165376]),\n"," array([-0.81947072, -0.33695172,  0.33047785])]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"yJLx9DuxzTKU","colab_type":"text"},"source":["### 11.1.1. Prediction"]},{"cell_type":"markdown","metadata":{"id":"XpayaE42zWQm","colab_type":"text"},"source":["* p features fed into input and then through weights into output (eg. only once without reupdating weights) "]},{"cell_type":"code","metadata":{"id":"h0ogNF5lzwIi","colab_type":"code","outputId":"10682a03-0c88-46cd-8609-9c1d045f9795","executionInfo":{"status":"ok","timestamp":1591034333104,"user_tz":420,"elapsed":3792,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["clf.predict_proba(X_test.iloc[0:1,:])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.17306485, 0.28039109, 0.54654406]])"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"xn6TN_VOjZsK","colab_type":"code","outputId":"3bdb0695-9a66-4319-ac18-4adb7fde28d1","executionInfo":{"status":"ok","timestamp":1591034333104,"user_tz":420,"elapsed":3778,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.metrics import accuracy_score\n","\n","y_pred= clf.predict(X_test)\n","accuracy_score(y_test, y_pred)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.25"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"X_FiPeiC9y82","colab_type":"text"},"source":["### 10.1.2. Hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"8JdPRggs92eB","colab_type":"text"},"source":["There ar many hyperparameters, but some of the useful ones include the setting of an adaptive learning rate or maximum number of iterations (m"]},{"cell_type":"markdown","metadata":{"id":"uUTH4vnn9wgz","colab_type":"text"},"source":["* `tol`: tolerance for the optimization\n","\n","  * When loss/score is not improving by at least `tol` for `n_iter_no_change` (default = 10) consecutive iterations (unless learning_rate is set to `adaptive`) convergence is considered to be reached (training stops)\n","\n","* `learning_rate` =`adaptive`:  keeps learning rate at `learning_rate_init` as long as training loss is decreasing (or score increasing) by at least `tol` for 2 consecutive epochs or else divided by 5 (used when solver='sgd')\n","\n","* `learning_rate_init`: step-size in updating the weights\n","\n","\n","* `max_iter`: max number of iterations\n","\n","  * iterates until convergence (determined by ‘tol’) or this number of iterations\n","\n","     * note that this determines the number of epochs\n"]},{"cell_type":"markdown","metadata":{"id":"dIC6o9kmej7J","colab_type":"text"},"source":["## 11.2. Pitfall: Issues with Convergence, Platforms, ect."]},{"cell_type":"markdown","metadata":{"id":"so59su-depKE","colab_type":"text"},"source":["* complexity of NN may require dealing with other issues\n","\n"]},{"cell_type":"markdown","metadata":{"id":"w8VHhiHxe373","colab_type":"text"},"source":["### 11.2.1. Convergence"]},{"cell_type":"markdown","metadata":{"id":"C99dJTIJe7dA","colab_type":"text"},"source":["* in contrast to SVM and linear models, NNs are non-convex meaning the solution is not unique\n","\n","  * for example if we swap the top circle/neuron with the botom one (along with the input lines) in the first layer we would have a different set of weights and the same minimum sum of squares\n","\n","* linear models are also non-iterative which means we have an explicit closed form solution."]},{"cell_type":"markdown","metadata":{"id":"nCzTEJnmlvoP","colab_type":"text"},"source":["## 11.3. Activation Functions\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dY2xtLcLl8-1","colab_type":"text"},"source":["* if our curve looks like that in figure 11-3 we may have a *vanishing gradient* issue meaning that even with a large LR we could take a long time to reach the min ( or with a very sharp curve we may have an *exploding gradient*)\n","\n","* "]},{"cell_type":"markdown","metadata":{"id":"bfqjGtz449jZ","colab_type":"text"},"source":["## 11.4. Regularization"]},{"cell_type":"markdown","metadata":{"id":"uY0ziiiJ5A-o","colab_type":"text"},"source":["remember that our weights are pretty much our new value of p so we would like to find some way of reducing the size\n","\n","* we could apply l1 or l1 regularization (similar to ridge, LASSO, or SVM\n","\n","  * note this wont reduce quantity due to loss function shape"]},{"cell_type":"markdown","metadata":{"id":"xmT_Q35Fk3tq","colab_type":"text"},"source":["### 11.4.2."]},{"cell_type":"markdown","metadata":{"id":"OsPAoCwBk57n","colab_type":"text"},"source":["* dropout will randomly remove a certain percentage of the weights for dimension reduction"]},{"cell_type":"markdown","metadata":{"id":"XugDJPwSlA-I","colab_type":"text"},"source":["## 11.5. Convergence Tricks"]},{"cell_type":"markdown","metadata":{"id":"-IRsDjSNlE7Y","colab_type":"text"},"source":["* ***scaling*** (or converting to between 0 and 1) is commonly used to ensure convergence is attained\n","\n","  * some packages do scaling by default\n","\n","* also ***learning rate adjustment*** can be used\n","\n","* in ***early stopping*** we stop when the performance on the validation set begins to deteriorate\n","\n","* we use can also use ***momentum*** which is a modified update rule (as shown below) in gradient descent\n","\n","* we update the weight using not just the learning rate times the gradient, but add a momentum factor (gamma) times the weight delta from the previous iteration\n","\n","    * eg. ADAM\n","\n","![alt text](https://visualstudiomagazine.com/articles/2017/08/01/~/media/ECG/visualstudiomagazine/Images/2017/08/0817vsm_McCaffreyFig1.ashx)"]},{"cell_type":"markdown","metadata":{"id":"YskIMhgDpeBu","colab_type":"text"},"source":["11.6. Fitting Neural Network "]},{"cell_type":"markdown","metadata":{"id":"hzBQzdBIpj7w","colab_type":"text"},"source":["### 11.6.1. Breast Cancer Data example"]},{"cell_type":"code","metadata":{"id":"uDHHMWxZbFpq","colab_type":"code","outputId":"318a699d-951f-46ac-e8df-549158768c5b","executionInfo":{"status":"ok","timestamp":1591034333105,"user_tz":420,"elapsed":3763,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.datasets import load_breast_cancer\n","cancer = load_breast_cancer()\n","\n","cancer.keys()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"PzCl20VYbJVN","colab_type":"code","outputId":"77330d71-b38f-4be7-cd58-994173765462","executionInfo":{"status":"ok","timestamp":1591034333105,"user_tz":420,"elapsed":3748,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["bc = pd.DataFrame(cancer['data'])\n","bc_y = pd.DataFrame(cancer['target'])\n","bc.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.99</td>\n","      <td>10.38</td>\n","      <td>122.80</td>\n","      <td>1001.0</td>\n","      <td>0.11840</td>\n","      <td>0.27760</td>\n","      <td>0.3001</td>\n","      <td>0.14710</td>\n","      <td>0.2419</td>\n","      <td>0.07871</td>\n","      <td>1.0950</td>\n","      <td>0.9053</td>\n","      <td>8.589</td>\n","      <td>153.40</td>\n","      <td>0.006399</td>\n","      <td>0.04904</td>\n","      <td>0.05373</td>\n","      <td>0.01587</td>\n","      <td>0.03003</td>\n","      <td>0.006193</td>\n","      <td>25.38</td>\n","      <td>17.33</td>\n","      <td>184.60</td>\n","      <td>2019.0</td>\n","      <td>0.1622</td>\n","      <td>0.6656</td>\n","      <td>0.7119</td>\n","      <td>0.2654</td>\n","      <td>0.4601</td>\n","      <td>0.11890</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>20.57</td>\n","      <td>17.77</td>\n","      <td>132.90</td>\n","      <td>1326.0</td>\n","      <td>0.08474</td>\n","      <td>0.07864</td>\n","      <td>0.0869</td>\n","      <td>0.07017</td>\n","      <td>0.1812</td>\n","      <td>0.05667</td>\n","      <td>0.5435</td>\n","      <td>0.7339</td>\n","      <td>3.398</td>\n","      <td>74.08</td>\n","      <td>0.005225</td>\n","      <td>0.01308</td>\n","      <td>0.01860</td>\n","      <td>0.01340</td>\n","      <td>0.01389</td>\n","      <td>0.003532</td>\n","      <td>24.99</td>\n","      <td>23.41</td>\n","      <td>158.80</td>\n","      <td>1956.0</td>\n","      <td>0.1238</td>\n","      <td>0.1866</td>\n","      <td>0.2416</td>\n","      <td>0.1860</td>\n","      <td>0.2750</td>\n","      <td>0.08902</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.69</td>\n","      <td>21.25</td>\n","      <td>130.00</td>\n","      <td>1203.0</td>\n","      <td>0.10960</td>\n","      <td>0.15990</td>\n","      <td>0.1974</td>\n","      <td>0.12790</td>\n","      <td>0.2069</td>\n","      <td>0.05999</td>\n","      <td>0.7456</td>\n","      <td>0.7869</td>\n","      <td>4.585</td>\n","      <td>94.03</td>\n","      <td>0.006150</td>\n","      <td>0.04006</td>\n","      <td>0.03832</td>\n","      <td>0.02058</td>\n","      <td>0.02250</td>\n","      <td>0.004571</td>\n","      <td>23.57</td>\n","      <td>25.53</td>\n","      <td>152.50</td>\n","      <td>1709.0</td>\n","      <td>0.1444</td>\n","      <td>0.4245</td>\n","      <td>0.4504</td>\n","      <td>0.2430</td>\n","      <td>0.3613</td>\n","      <td>0.08758</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11.42</td>\n","      <td>20.38</td>\n","      <td>77.58</td>\n","      <td>386.1</td>\n","      <td>0.14250</td>\n","      <td>0.28390</td>\n","      <td>0.2414</td>\n","      <td>0.10520</td>\n","      <td>0.2597</td>\n","      <td>0.09744</td>\n","      <td>0.4956</td>\n","      <td>1.1560</td>\n","      <td>3.445</td>\n","      <td>27.23</td>\n","      <td>0.009110</td>\n","      <td>0.07458</td>\n","      <td>0.05661</td>\n","      <td>0.01867</td>\n","      <td>0.05963</td>\n","      <td>0.009208</td>\n","      <td>14.91</td>\n","      <td>26.50</td>\n","      <td>98.87</td>\n","      <td>567.7</td>\n","      <td>0.2098</td>\n","      <td>0.8663</td>\n","      <td>0.6869</td>\n","      <td>0.2575</td>\n","      <td>0.6638</td>\n","      <td>0.17300</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>20.29</td>\n","      <td>14.34</td>\n","      <td>135.10</td>\n","      <td>1297.0</td>\n","      <td>0.10030</td>\n","      <td>0.13280</td>\n","      <td>0.1980</td>\n","      <td>0.10430</td>\n","      <td>0.1809</td>\n","      <td>0.05883</td>\n","      <td>0.7572</td>\n","      <td>0.7813</td>\n","      <td>5.438</td>\n","      <td>94.44</td>\n","      <td>0.011490</td>\n","      <td>0.02461</td>\n","      <td>0.05688</td>\n","      <td>0.01885</td>\n","      <td>0.01756</td>\n","      <td>0.005115</td>\n","      <td>22.54</td>\n","      <td>16.67</td>\n","      <td>152.20</td>\n","      <td>1575.0</td>\n","      <td>0.1374</td>\n","      <td>0.2050</td>\n","      <td>0.4000</td>\n","      <td>0.1625</td>\n","      <td>0.2364</td>\n","      <td>0.07678</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      0      1       2       3   ...      26      27      28       29\n","0  17.99  10.38  122.80  1001.0  ...  0.7119  0.2654  0.4601  0.11890\n","1  20.57  17.77  132.90  1326.0  ...  0.2416  0.1860  0.2750  0.08902\n","2  19.69  21.25  130.00  1203.0  ...  0.4504  0.2430  0.3613  0.08758\n","3  11.42  20.38   77.58   386.1  ...  0.6869  0.2575  0.6638  0.17300\n","4  20.29  14.34  135.10  1297.0  ...  0.4000  0.1625  0.2364  0.07678\n","\n","[5 rows x 30 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"4C9jDxUEdP1B","colab_type":"code","outputId":"0e7b45d9-3049-46db-ed1d-179ea14a70a7","executionInfo":{"status":"ok","timestamp":1591034333105,"user_tz":420,"elapsed":3733,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["bc.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(569, 30)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"pbRtD5rHbK8M","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(bc, bc_y)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GSMte-MDcpw6","colab_type":"text"},"source":["* lets try scaling to see if it helps convergence\n","\n","* it seems to help accuracy"]},{"cell_type":"code","metadata":{"id":"-uAijTrwbPop","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","\n","scaler.fit(X_train)\n","\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0WXzDLj_M3s5","colab_type":"text"},"source":["* lets try as many layers as features"]},{"cell_type":"code","metadata":{"id":"oPHdVCuZbTiI","colab_type":"code","outputId":"9180faf1-34d7-4aaf-a737-8e75cb79a993","executionInfo":{"status":"ok","timestamp":1591034333918,"user_tz":420,"elapsed":4519,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":258}},"source":["from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import classification_report,confusion_matrix\n","\n","# 3 layers 30 neurons/layer \n","clf = MLPClassifier(hidden_layer_sizes=(30,30,30))\n","\n","\n","clf.fit(X_train,y_train)\n","\n","\n","print()\n","y_pred = clf.predict(X_test)\n","print()\n","accuracy_score(y_test, y_pred)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["[[43  6]\n"," [ 1 93]]\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.88      0.92        49\n","           1       0.94      0.99      0.96        94\n","\n","    accuracy                           0.95       143\n","   macro avg       0.96      0.93      0.94       143\n","weighted avg       0.95      0.95      0.95       143\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VxdlsbQDuCUU","colab_type":"text"},"source":["* `coefs_[i] ` weight matrices between layer i and layer i+1\n","\n","* `intercepts_[i]` bias vectors added to layer i+1"]},{"cell_type":"code","metadata":{"id":"IgMoK5rWwfIN","colab_type":"code","outputId":"8aa451e3-cba1-4c5d-f290-fcbbdaa49e08","executionInfo":{"status":"ok","timestamp":1591034333921,"user_tz":420,"elapsed":4509,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# weights per layer\n","len(clf.coefs_[0])"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["30"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"yKLww5lKxI14","colab_type":"code","outputId":"7f22846e-4bb1-40ea-dbc5-4f2deab61e4f","executionInfo":{"status":"ok","timestamp":1591034333922,"user_tz":420,"elapsed":4497,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# layers including output\n","len(clf.coefs_)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"Jhu4-pjfty7C","colab_type":"code","outputId":"f3cec6d1-a106-461e-9974-9fa1c582ca92","executionInfo":{"status":"ok","timestamp":1591034333923,"user_tz":420,"elapsed":4485,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":340}},"source":["clf.intercepts_"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([-0.03681759,  0.1726946 , -0.01077704, -0.21764019,  0.18954937,\n","         0.23760169, -0.02629925,  0.33132044,  0.23864519, -0.1809671 ,\n","         0.22604855,  0.21129482,  0.29982368,  0.42792994, -0.03545507,\n","        -0.24234831, -0.2517509 ,  0.28436397,  0.0207698 ,  0.07590619,\n","         0.14254272, -0.15152401,  0.06133646,  0.24956177, -0.11689575,\n","         0.04504144, -0.26928886,  0.34279583,  0.09353027, -0.16461493]),\n"," array([ 0.08292715, -0.04508507, -0.24826857,  0.06094625,  0.01442469,\n","        -0.10336484,  0.03531113, -0.15584774, -0.07768522,  0.09098652,\n","         0.26873999,  0.05291085,  0.05009212, -0.07490764,  0.19832722,\n","        -0.00206966, -0.02598817,  0.335719  , -0.25091081, -0.25189414,\n","         0.12527096, -0.25643678, -0.06456207, -0.25735071,  0.04322971,\n","         0.06396341,  0.29060605,  0.1657436 ,  0.10089951,  0.12085279]),\n"," array([-0.1233255 ,  0.02190778,  0.22945016,  0.09904069,  0.09214511,\n","         0.37189609,  0.28433826,  0.00058068, -0.2538425 , -0.00854994,\n","         0.09994361,  0.07142726, -0.18349598,  0.32960056,  0.0597549 ,\n","         0.11624216,  0.28794836,  0.33697503,  0.14603639, -0.02832984,\n","         0.21943708,  0.23271006,  0.27733606, -0.0102105 ,  0.05429451,\n","         0.28208486, -0.04647765,  0.01406697, -0.01016684, -0.24063027]),\n"," array([0.39597727])]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"F614faW-gRM9","colab_type":"text"},"source":["### 11.6.2. Hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"APldB6R5gyZV","colab_type":"text"},"source":["* many are used for improving the convergence behaviour such as early stopping, LR, and adaptive methods"]},{"cell_type":"markdown","metadata":{"id":"ueLabXfoeHRM","colab_type":"text"},"source":["### 11.6.3. Grid Search: BC Data"]},{"cell_type":"code","metadata":{"id":"ZMiAYRTr0c7j","colab_type":"code","colab":{}},"source":["from sklearn.neural_network import MLPClassifier\n","mlp = MLPClassifier()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fuABv-jIgCrq","colab_type":"text"},"source":["* lets try different solvers, activation functions, numbers of layers/neurons, and epochs...\n","\n","* we could also try changing alpha (the L2 penatly regularization term)\n","\n","* "]},{"cell_type":"code","metadata":{"id":"gyzKWgbRgFvO","colab_type":"code","colab":{}},"source":["parameter_space = {\n","    'hidden_layer_sizes': [(30,30,30), (10,10,), (30,)],\n","    #'activation': ['tanh', 'relu'],\n","    'solver': ['sgd', 'adam'],\n","    #'learning_rate': ['constant','adaptive'],\n","    'max_iter': [10, 50, 100]#, 300]\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OKFJwdPJ043Z","colab_type":"text"},"source":["* `n_jobs` is to sets number of CPU cores from your computer to use (-1 for all cores available)\n","\n","* `cv ` sets number of splits for cross-validation"]},{"cell_type":"markdown","metadata":{"id":"zIJslFV-1czW","colab_type":"text"},"source":["* sklearn has hyper-parameter optimization tools.\n","\n","  * GridSearchCV\n","  * RandomizedSearchCV"]},{"cell_type":"code","metadata":{"id":"mM182XkLtBpd","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import GridSearchCV\n","\n","clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=7)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WdFuqBU4tAO","colab_type":"code","outputId":"4f8b02fb-7779-4367-c74a-a7d4d9a86761","executionInfo":{"status":"ok","timestamp":1591035064614,"user_tz":420,"elapsed":8772,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":615}},"source":["clf.fit(X_train, y_train)\n","\n","print(\"Best parameters set found on development set:\")\n","print()\n","print(clf.best_params_)\n","print()\n","print(\"Grid scores on development set:\")\n","print()\n","means = clf.cv_results_['mean_test_score']\n","stds = clf.cv_results_['std_test_score']\n","for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n","    print(\"%0.3f (+/-%0.03f) for %r\"\n","          % (mean, std * 2, params))\n","print()\n","\n","\n","print(\"The model is trained on the full development set.\")\n","print(\"The scores are computed on the full evaluation set.\")\n","print()\n","y_pred = clf.predict(X_test)\n","\n","print()\n","accuracy_score(y_test, y_pred)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"],"name":"stderr"},{"output_type":"stream","text":["Best parameters set found on development set:\n","\n","{'hidden_layer_sizes': (30, 30, 30), 'max_iter': 100, 'solver': 'adam'}\n","\n","Grid scores on development set:\n","\n","0.512 (+/-0.268) for {'hidden_layer_sizes': (30, 30, 30), 'max_iter': 10, 'solver': 'sgd'}\n","0.927 (+/-0.058) for {'hidden_layer_sizes': (30, 30, 30), 'max_iter': 10, 'solver': 'adam'}\n","0.883 (+/-0.130) for {'hidden_layer_sizes': (30, 30, 30), 'max_iter': 50, 'solver': 'sgd'}\n","0.962 (+/-0.045) for {'hidden_layer_sizes': (30, 30, 30), 'max_iter': 50, 'solver': 'adam'}\n","0.941 (+/-0.055) for {'hidden_layer_sizes': (30, 30, 30), 'max_iter': 100, 'solver': 'sgd'}\n","0.986 (+/-0.021) for {'hidden_layer_sizes': (30, 30, 30), 'max_iter': 100, 'solver': 'adam'}\n","0.523 (+/-0.360) for {'hidden_layer_sizes': (10, 10), 'max_iter': 10, 'solver': 'sgd'}\n","0.625 (+/-0.365) for {'hidden_layer_sizes': (10, 10), 'max_iter': 10, 'solver': 'adam'}\n","0.831 (+/-0.193) for {'hidden_layer_sizes': (10, 10), 'max_iter': 50, 'solver': 'sgd'}\n","0.953 (+/-0.054) for {'hidden_layer_sizes': (10, 10), 'max_iter': 50, 'solver': 'adam'}\n","0.891 (+/-0.219) for {'hidden_layer_sizes': (10, 10), 'max_iter': 100, 'solver': 'sgd'}\n","0.974 (+/-0.024) for {'hidden_layer_sizes': (10, 10), 'max_iter': 100, 'solver': 'adam'}\n","0.744 (+/-0.281) for {'hidden_layer_sizes': (30,), 'max_iter': 10, 'solver': 'sgd'}\n","0.808 (+/-0.345) for {'hidden_layer_sizes': (30,), 'max_iter': 10, 'solver': 'adam'}\n","0.941 (+/-0.061) for {'hidden_layer_sizes': (30,), 'max_iter': 50, 'solver': 'sgd'}\n","0.960 (+/-0.046) for {'hidden_layer_sizes': (30,), 'max_iter': 50, 'solver': 'adam'}\n","0.962 (+/-0.045) for {'hidden_layer_sizes': (30,), 'max_iter': 100, 'solver': 'sgd'}\n","0.974 (+/-0.016) for {'hidden_layer_sizes': (30,), 'max_iter': 100, 'solver': 'adam'}\n","\n","The model is trained on the full development set.\n","The scores are computed on the full evaluation set.\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.958041958041958"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"VA1xxfvuC8y7","colab_type":"text"},"source":["* it looks like more than 10 iterations are required\n","\n","* Adam also usually produces higher accuracy\n","\n","* also combinations of 30 neurons/layer \n","\n","* note that the number of epochs is determined by max iterations since iterations stop when the max is reached\n","\n","* remember that in each epoch we go through all of the training examples"]},{"cell_type":"markdown","metadata":{"id":"cTP8F_0aajcx","colab_type":"text"},"source":["## 11.9. Relation to Polynomial Regression"]},{"cell_type":"markdown","metadata":{"id":"mweS_-igyt_G","colab_type":"text"},"source":["* we are summing the features and running them through an activation function which acts similar to the polynomial\n","\n","\n","* eg. if we had the activation function t^2  we would also have the squared terms\n","\n","* and another layer would be the 4th power of each term\n","\n","\n","* the activation functions can also usually be approximated by polynomials\n","\n","\n","\n","* minimizes sum of squared errors"]},{"cell_type":"markdown","metadata":{"id":"sax3dOmzpMAH","colab_type":"text"},"source":["# CNN"]},{"cell_type":"markdown","metadata":{"id":"yMXAz5MgYKta","colab_type":"text"},"source":["* Let’s design a CNN for a MNIST demo in Keras\n","\n","* **Keras** is a popular deep learning API\n","\n","  * built on top of Tensorflow\n","\n","* the output/input shapes are 3D tensors\n","\n","  * input tensor of size (28, 28, 1) (the image size)\n","\n","  * if we had a color image it would be 3 channels\n","\n","  * the number of kernels is the first parameter to conv2D\n","\n","* say we use a conv filter size of 5 x 5 with RelU activation and 2 X 2 max pooling\n","\n","\n","* summary can give us a table of layer shapes and the number of parameters\n","\n"]},{"cell_type":"code","metadata":{"id":"yOt_1anApMjE","colab_type":"code","outputId":"72f9eebe-50ec-4f38-8e83-8087d0b3b478","executionInfo":{"status":"ok","timestamp":1591304777517,"user_tz":420,"elapsed":10632,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["from keras import layers\n","from keras import models\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32,(5,5),activation='relu',input_shape=(28, 28,1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 24, 24, 32)        832       \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n","=================================================================\n","Total params: 832\n","Trainable params: 832\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bC3wIdApAeHj","colab_type":"text"},"source":["* **param #** stands for the number of parameters of the conv2D layer \n","\n","* eg. weight matrix of window size 5×5 and a bias for each of the filters is 832 parameters (32 × (25 + 1))\n","  * +1 for bias term \n","\n","* **Max-pooling** then takes the max of each window reducing the number of inputs to the next layer by 1/2 to 12\n","\n","    * for every 2 elements in each direction we have the max\n","\n","  * does not add params since it is an operation\n"]},{"cell_type":"markdown","metadata":{"id":"f3MU3Lw_56L8","colab_type":"text"},"source":["## Adding more layers \n","\n","* as we add more layers height and width reduce, while features increase\n","\n","* the number of input channels will be 32 since that is the number of features from the previous layer\n","  \n","  * Keras will calculate this for us though\n","\n","* adding 64 5 × 5 window filters and a 2 × 2 pooling layer gives us a total of ((5 × 5 × 32) + 1) ×64 = 51264\n","  "]},{"cell_type":"code","metadata":{"id":"SuF-V4x2rNRd","colab_type":"code","outputId":"09c9b978-831e-4bdb-a66b-e90d97543756","executionInfo":{"status":"ok","timestamp":1591304777518,"user_tz":420,"elapsed":8878,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32,(5,5),activation='relu', \n","                                 input_shape=(28,28,1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_2 (Conv2D)            (None, 24, 24, 32)        832       \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 12, 12, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 8, 8, 64)          51264     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 4, 4, 64)          0         \n","=================================================================\n","Total params: 52,096\n","Trainable params: 52,096\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dsk3_aeSP6LB","colab_type":"text"},"source":["* after the second max-pooling layer we have 4 by 4 h by w dimensions\n","\n","* next we will add a ***densely connected layer*** with **softmax** for final classification\n","\n","\n","* to do this the previous output vector is first flattened to 1024 \n","\n","  * since the number of possible outputs is 10 we now have 10 + 1024 parameters\n","\n","    * softmax squashes a vector of output scores (each of the elements in the flattened output) to the range (0, 1) so all the resulting elements probabilities add up to 1. It is applied to the output scores:\n","\n","\n","> ![alt text](https://latex.codecogs.com/gif.latex?f(s)_{i}&space;=&space;\\frac{e^{s_{i}}}{\\sum_{j}^{C}&space;e^{s_{j}}})\n"]},{"cell_type":"code","metadata":{"id":"nsQCsM4JSP-Q","colab_type":"code","outputId":"b9497df7-d8d4-41c1-d741-373bb3700a66","executionInfo":{"status":"ok","timestamp":1591304777518,"user_tz":420,"elapsed":7160,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32,(5,5),activation='relu', \n","                                 input_shape=(28,28,1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (5, 5), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(10, activation='softmax'))\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_4 (Conv2D)            (None, 24, 24, 32)        832       \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n","_________________________________________________________________\n","conv2d_5 (Conv2D)            (None, 8, 8, 64)          51264     \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 4, 4, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                10250     \n","=================================================================\n","Total params: 62,346\n","Trainable params: 62,346\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mOYFkG4asBdC","colab_type":"text"},"source":["![alt text](https://miro.medium.com/max/1400/1*CKgnKTEITrPKaDiG_536Mg.png)"]},{"cell_type":"markdown","metadata":{"id":"Ca7fPKDHsIsy","colab_type":"text"},"source":["## Training and evaluation"]},{"cell_type":"markdown","metadata":{"id":"Xm6EwDQSSmLS","colab_type":"text"},"source":["* all the paramaters of the convolutional layers are adjusted during training"]},{"cell_type":"code","metadata":{"id":"hOVitttfrR4z","colab_type":"code","outputId":"1ca3d308-7a2d-4f23-9db4-18a1f825a5cf","executionInfo":{"status":"ok","timestamp":1591304777519,"user_tz":420,"elapsed":5110,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["from keras.datasets import mnist\n","from keras.utils import to_categorical\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","print('X_train.shape')\n","print(X_train.shape)\n","print('X_test.shape')\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["X_train.shape\n","(60000, 28, 28)\n","X_test.shape\n","(10000, 28, 28)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gsuUNz9l0aNG","colab_type":"text"},"source":["* reshape into 4D tensors\n","\n","* make sue everything is of proper type"]},{"cell_type":"code","metadata":{"id":"DWzCaD4FyxJ7","colab_type":"code","colab":{}},"source":["X_train = X_train.reshape((60000, 28, 28, 1))\n","X_train = X_train.astype('float32') / 255\n","X_test = X_test.reshape((10000, 28, 28, 1))\n","X_test = X_test.astype('float32') / 255\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zWCc_TB3_j22","colab_type":"text"},"source":["* similar to NN we choose the optimizer and loss function\n","\n","\n","* we use a Softmax activation plus a **Cross-Entropy loss** to output class probability for each image\n","\n","  * used for multi-class classification\n","\n","\n","\n","![alt text](https://gombru.github.io/assets/cross_entropy_loss/softmax_CE_pipeline.png)\n","\n","\n","* In Multi-Class classification the labels are one-hot, so only the positive class keeps its term in the loss"]},{"cell_type":"code","metadata":{"id":"TDhIeMniyw0x","colab_type":"code","outputId":"3fa1a2b0-ad5a-4ff5-bc07-230a2f62c25d","executionInfo":{"status":"ok","timestamp":1591304797385,"user_tz":420,"elapsed":21048,"user":{"displayName":"Robin Yancey","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg1Mgq9pKcR0qfYMWBX5nKU1OYkU75h8XMWnSc=s64","userId":"13168997243252415066"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer='sgd',\n","              metrics=['accuracy'])\n","model.fit(X_train, y_train,\n","          batch_size=100,\n","          epochs=5,\n","          verbose=1)\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print('Test accuracy:', test_acc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","60000/60000 [==============================] - 9s 154us/step - loss: 0.8490 - accuracy: 0.7830\n","Epoch 2/5\n","60000/60000 [==============================] - 2s 40us/step - loss: 0.2576 - accuracy: 0.9245\n","Epoch 3/5\n","60000/60000 [==============================] - 2s 41us/step - loss: 0.1853 - accuracy: 0.9461\n","Epoch 4/5\n","60000/60000 [==============================] - 2s 41us/step - loss: 0.1477 - accuracy: 0.9565\n","Epoch 5/5\n","60000/60000 [==============================] - 2s 39us/step - loss: 0.1252 - accuracy: 0.9637\n","10000/10000 [==============================] - 1s 67us/step\n","Test accuracy: 0.9664999842643738\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GbcVOyDcIWRG","colab_type":"text"},"source":["* takes much longer on CPU\n"]}]}